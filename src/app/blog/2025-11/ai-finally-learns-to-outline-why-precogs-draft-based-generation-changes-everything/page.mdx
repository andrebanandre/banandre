---
title: >-
  AI Finally Learns to Outline: Why Precog's Draft-Based Generation Changes
  Everything
description: >-
  New 24B and 123B Precog models write internal drafts before responses,
  delivering smarter outputs with less computational overhead.
slug: >-
  ai-finally-learns-to-outline-why-precogs-draft-based-generation-changes-everything
image: >-
  /blog/2025/ai-finally-learns-to-outline-why-precogs-draft-based-generation-changes-everything.webp
date: 2025-11-17T00:00:00.000Z
tags: &ref_0
  - ai-models
  - reasoning
  - llm-architecture
  - fine-tuning
categories:
  - Artificial Intelligence
author: Banandre
type: article
openGraph:
  type: article
  title: >-
    AI Finally Learns to Outline: Why Precog's Draft-Based Generation Changes
    Everything
  description: >-
    New 24B and 123B Precog models write internal drafts before responses,
    delivering smarter outputs with less computational overhead.
  url: >-
    https://banandre.com/blog/2025-11/ai-finally-learns-to-outline-why-precogs-draft-based-generation-changes-everything
  siteName: Banandre
  images:
    - url: >-
        https://banandre.com/blog/2025/ai-finally-learns-to-outline-why-precogs-draft-based-generation-changes-everything.webp
      width: 1200
      height: 630
      alt: >-
        AI Finally Learns to Outline: Why Precog's Draft-Based Generation
        Changes Everything
  publishedTime: '2025-11-17T00:00:00.000Z'
  authors:
    - Banandre
  tags: *ref_0
  section: Artificial Intelligence
twitter:
  card: summary_large_image
  site: '@banandre'
  creator: '@banandre'
  title: >-
    AI Finally Learns to Outline: Why Precog's Draft-Based Generation Changes
    Everything
  description: >-
    New 24B and 123B Precog models write internal drafts before responses,
    delivering smarter outputs with less computational overhead.
  images:
    - >-
      https://banandre.com/blog/2025/ai-finally-learns-to-outline-why-precogs-draft-based-generation-changes-everything.webp
jsonLd:
  '@context': 'https://schema.org'
  '@type': BlogPosting
  headline: >-
    AI Finally Learns to Outline: Why Precog's Draft-Based Generation Changes
    Everything
  description: >-
    New 24B and 123B Precog models write internal drafts before responses,
    delivering smarter outputs with less computational overhead.
  image: >-
    https://banandre.com/blog/2025/ai-finally-learns-to-outline-why-precogs-draft-based-generation-changes-everything.webp
  url: >-
    https://banandre.com/blog/2025-11/ai-finally-learns-to-outline-why-precogs-draft-based-generation-changes-everything
  datePublished: '2025-11-17T00:00:00.000Z'
  dateModified: '2025-11-17T00:00:00.000Z'
  author:
    '@type': Person
    name: Banandre
    url: 'https://banandre.com'
  publisher:
    '@type': Organization
    name: Banandre
    url: 'https://banandre.com'
    logo:
      '@type': ImageObject
      url: 'https://banandre.com/banana.png'
  mainEntityOfPage:
    '@type': WebPage
    '@id': >-
      https://banandre.com/blog/2025-11/ai-finally-learns-to-outline-why-precogs-draft-based-generation-changes-everything
---


The fundamental problem with today's large language models isn't intelligence, it's planning. Most LLMs operate like improv comedians forced to deliver Shakespeare: they generate text token-by-token with no blueprint, no outline, and no chance for revision. The result? Inconsistent narratives, logical gaps, and responses that start strong but wander into incoherence.

Enter **Precog AI**, a new approach from TheDrummer that introduces what might be the most intuitive advancement in reasoning architecture since chain-of-thought itself. Instead of complex reasoning pipelines that generate thousands of tokens of internal monologue, Precog models [write a short draft first](https://huggingface.co/TheDrummer/Precog-24B-v1), then use that blueprint to construct the final response. It's embarrassingly simple yet surprisingly effective.

![Precog AI models introduce draft-based response generation](/blog/2025/precog-ai-models-introduce-draft-based-response-generation.webp)


## The Anatomy of Precog: Draft-First Reasoning Explained

Traditional reasoning models like Behemoth R1 and Cydonia R1 approach complex questions like mathematicians solving equations, breaking down problems step-by-step, checking logic, and ensuring correctness. They're the meticulous scholars of the AI world. Precog takes a different approach entirely: it's the writer who sketches an outline before typing the manuscript.

The implementation is deceptively simple. Using the familiar `<think>` format, Precog generates what founder TheDrummer describes as "a simple, digestible draft" that serves as the foundation for the actual response. This isn't complex logical reasoning, it's narrative planning. The model creates what amounts to a synopsis or abstract, then fleshes it out into the final output.

The genius lies in what this approach avoids: the exponential hallucination risk that plagues lengthy reasoning chains. As one analysis of reasoning models demonstrates, hallucination probability grows exponentially with token count. If the probability of any single token being a hallucination is P, then the probability of hallucination in N tokens is 1-(1-P)^N. For a typical reasoning phase of 500 tokens versus Precog's brief draft of around 100 tokens, the difference in reliability isn't linear, it's substantial.

## Precog vs. Traditional Reasoning: A Clear Architectural Divide

The distinction between Precog and conventional reasoning models becomes stark when you examine their approaches side-by-side. Traditional models treat prompts as problems to be solved, they engage in what essentially amounts to mathematical reasoning, even for creative tasks. Developers report that earlier reasoning models "seemed like the reasoning was treating RP prompts/cards like an equation or science problem to solve for."

Precog models flip this paradigm entirely. As TheDrummer explains, the models provide "an overview of the response" rather than breaking down questions and finding solutions. The draft becomes a narrative skeleton, a plot summary for roleplaying scenarios, a structural outline for stories, or a high-level plan for complex instructions.

This architectural shift has profound implications for coherence and narrative flow. Where other models might lose track of character details or plot points over extended conversations, Precog's draft-first approach creates what users describe as "lazer sharp, super quick, and more RP context aware" responses. The model "seems to remember what it's doing better and execute in a logical sequence."

## The Mathematical Advantage: Token Efficiency Meets Reliability

The recent [InTRO (In-Token Rationality Optimization) research](https://arxiv.org/html/2511.09865) provides the theoretical backbone for why draft-based approaches work. The paper demonstrates that "token-level exploration with self-generated feedback" enables more accurate and concise reasoning paths. While Precog wasn't trained using InTRO specifically, it embodies similar principles: shorter reasoning phases lead to fewer cumulative error opportunities.

The data speaks clearly: across mathematical reasoning benchmarks, InTRO-aligned models achieved up to 20% accuracy improvements over base models while producing significantly shorter rationales. The researchers found that "InTRO produces rationales that are remarkably shorter than strong RL baselines while lifting accuracy." This isn't just about efficiency, it's about reducing the surface area for errors while maintaining quality.

Precog takes this concept further by optimizing for creative domains rather than mathematical precision. The feedback from early adopters suggests this trade-off pays dividends: "First reasoning model that really felt like its reasoning was finetuned for RP/stories", one user noted. The model creates "a skeletal synopsis of the final output which makes much more sense for reasoning in RP/storywriting."

## Practical Applications: Where Draft-Based Reasoning Shines

The real test comes in deployment, and Precog's draft-first approach demonstrates particular strength in several key areas:

**Long-form narrative coherence** emerges as Precog's standout capability. The ability to plan character development, maintain consistent pacing, and remember plot details across extended conversations gives it a distinct edge over models that generate responses reactively. Users report reaching "a 28k context window and it's quite stable", a significant achievement for any 24B parameter model.

**User control and customization** represents another advantage. Because the draft phase uses standard `<think>` formatting, users can prefill or edit the draft content to steer responses in specific directions. Want a character to approach a situation differently? Modify the draft. Need a particular tone or pacing? Adjust the outline. This level of intervention isn't possible with black-box reasoning processes.

**Computational efficiency** shouldn't be underestimated either. While the 123B model requires substantial resources, the 24B version delivers sophisticated reasoning at a fraction of the computational cost of larger alternatives. The brief draft phase means you're not paying for hundreds of tokens of internal monologue, just enough planning to ensure coherence.

## The Limitations: When Planning Isn't Enough

Precog's approach isn't a silver bullet, and TheDrummer acknowledges its weaknesses. The model's draft might not always align perfectly with the final response, creating occasional dissonance between plan and execution. More significantly, conventional reasoning models still outperform when handling subtle nuance and complex logical relationships.

The trade-off becomes clear: Precog excels at narrative flow and creative coherence while traditional reasoning models maintain advantages in analytical precision. As one commenter noted, "Cydonia R1 4.1 does nuance on a moment to moment basis good and has given me some really 'human' responses that way."

For developers working on mathematical proofs, complex code generation, or tasks requiring meticulous step-by-step verification, traditional reasoning approaches might still be preferable. Precog shines brightest when the goal isn't perfect correctness but compelling coherence.

## The Future of Draft-Based Architectures

What makes Precog truly compelling isn't just its current capabilities but its architectural implications. The concept of draft-first generation feels like a missing piece in the AI toolchain, a way to inject planning and structure without the overhead of complex reasoning pipelines.

This approach represents a middle ground between raw autoregressive generation and full reasoning architectures. It offers the coherence benefits of planning without the computational cost of exhaustive logical breakdowns. For creative applications, roleplaying, storytelling, and any domain where narrative continuity matters, draft-based generation could become the default approach.

The emergence of models like Precog suggests we're moving beyond one-size-fits-all reasoning architectures. Different tasks require different types of thinking, and sometimes what you need isn't a mathematical proof but a well-structured outline. As AI models become increasingly specialized, draft-based generation might become the standard approach for any application where flow matters more than formal correctness.

**Bottom line:** Precog won't solve mathematical proofs better than specialized reasoning models, but for creative writing, roleplaying, and narrative generation, its draft-first approach delivers something most models struggle with: consistent, coherent storytelling that feels planned rather than improvised. Sometimes the best thinking happens before you start writing at all.
